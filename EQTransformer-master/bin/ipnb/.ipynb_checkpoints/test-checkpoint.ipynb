{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "f = h5py.File('../ModelsAndSampleData/100samples.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_name(name):\n",
    "    print(name)\n",
    "f.visit(print_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate one \"station_name.hdf5\" and one \"station_name.csv\" file for each of your stations and put them into a directory named \"mseed_dir+_hdfs\". Then you need is to pass the name of the directory containing your hdf5 & CSV files and a model. You can use relatively low threshold values for the detection and picking since EQTransformer is very robust to false positives. Enaibeling uncertaintiy estimation, outputing probabilities, or plotting all the detected events will slow down the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 E 中的卷是 Download & Documents\n",
      " 卷的序列号是 0234-A30F\n",
      "\n",
      " E:\\Working_Documents\\200902EQTransformer-master\\examples 的目录\n",
      "\n",
      "2020/09/03  01:36    <DIR>          .\n",
      "2020/09/03  01:36    <DIR>          ..\n",
      "2020/09/02  20:29    <DIR>          .ipynb_checkpoints\n",
      "2020/08/10  13:14             4,968 association.ipynb\n",
      "2020/09/02  20:29            16,826 detection.ipynb\n",
      "2020/09/02  20:27            29,285 downloading.ipynb\n",
      "2020/09/03  01:36            66,120 test.ipynb\n",
      "2020/08/10  13:14            31,671 training.ipynb\n",
      "2020/08/10  13:14             4,025 visualization.ipynb\n",
      "               6 个文件        152,895 字节\n",
      "               3 个目录 363,098,451,968 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Running EqTransformer  None\n",
      " *** Loading the model ...\n",
      "*** Loading is complete!\n",
      "######### There are files for 1 stations in ../hdfs/ directory. #########\n",
      "========= Started working on 100samples, 1 out of 1 ...\n",
      "  0%|                                                                         | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 2 minutes and 22.84 seconds.\n",
      " *** Detected: 99 events.\n",
      " *** Wrote the results into --> \" E:\\Working_Documents\\200902EQTransformer-master\\examples\\detections1\\100samples_outputs \"\n",
      "100%|████████████████████████████████████████████████████████████████| 1/1 [02:15<00:00, 135.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.predictor import predictor\n",
    "predictor(input_dir='../hdfs/',   \n",
    "         input_model='../ModelsAndSampleData/EqT_model.h5',\n",
    "         output_dir='detections1',\n",
    "         estimate_uncertainty=False, \n",
    "         output_probabilities=False,\n",
    "         number_of_sampling=5,\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.1,\n",
    "         S_threshold=0.1, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time',\n",
    "         batch_size=500,\n",
    "         number_of_cpus=4,\n",
    "         keepPS=False,\n",
    "         spLimit=60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option (II) directly on downloaded MiniSeed files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform the detection/picking directly on .mseed files. \n",
    "This save both prerpcessing time and the extra space needed for hdf5 file. However, it can be more memory intensive. So it is recommended when mseed fils are one month long or shorter.\n",
    "This option also does not allow you to estimate the uncertainties, write the prediction probabilities, or use the advantages of having hdf5 files which makes it easy to access the raw event waveforms based on detection results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Running EqTransformer  None\n",
      " *** Loading the model ...\n",
      "*** Loading is complete!\n",
      "######### There are files for 3 stations in downloads_mseeds directory. #########\n",
      "========= Started working on B921, 1 out of 3 ...\n",
      "20190901T000000Z__20190902T000000Z.mseed\n",
      "\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 1 minutes and 10.13 seconds.\n",
      " *** Detected: 1393 events.\n",
      " *** Wrote the results into --> \" /Users/mostafamousavi/Desktop/EQTransformer/examples/detections2/B921_outputs \"\n",
      "========= Started working on CA06, 2 out of 3 ...\n",
      "20190901T000000Z__20190902T000000Z.mseed\n",
      "\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 0 minutes and 32.47 seconds.\n",
      " *** Detected: 1345 events.\n",
      " *** Wrote the results into --> \" /Users/mostafamousavi/Desktop/EQTransformer/examples/detections2/CA06_outputs \"\n",
      "========= Started working on SV08, 3 out of 3 ...\n",
      "20190901T000000Z__20190902T000000Z.mseed\n",
      "\n",
      "\n",
      " *** Finished the prediction in: 0 hours and 0 minutes and 29.27 seconds.\n",
      " *** Detected: 801 events.\n",
      " *** Wrote the results into --> \" /Users/mostafamousavi/Desktop/EQTransformer/examples/detections2/SV08_outputs \"\n"
     ]
    }
   ],
   "source": [
    "from EQTransformer.core.mseed_predictor import mseed_predictor\n",
    "mseed_predictor(input_dir='downloads_mseeds',   \n",
    "         input_model='../ModelsAndSampleData/EqT_model.h5',\n",
    "         stations_json='station_list.json',\n",
    "         output_dir='detections2',\n",
    "         loss_weights=[0.02, 0.40, 0.58],          \n",
    "         detection_threshold=0.3,                \n",
    "         P_threshold=0.1,\n",
    "         S_threshold=0.1, \n",
    "         number_of_plots=10,\n",
    "         plot_mode='time_frequency',\n",
    "         normalization_mode='std',\n",
    "         batch_size=500,\n",
    "         overlap=0.3,\n",
    "         gpuid=None,\n",
    "         gpu_limit=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction outputs for each station will be written in your output directory (i.e. 'detections').\n",
    "\n",
    "'X_report.txt' contains processing info on input parameters used for the detection/picking and final \n",
    "results such as running time, the total number of detected events (these are unique events and duplicated ones have been already removed). \n",
    "\n",
    "'X_prediction_results.csv' contains detection/picking results in the figures folder you can find the plots for the number of events that you specified in the above comment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
